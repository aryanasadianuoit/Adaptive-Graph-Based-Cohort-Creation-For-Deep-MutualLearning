{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KD_Different_Methods.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtPAvcPs9lnKYS4PtUyx5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryanasadianuoit/Adaptive-Graph-Based-Cohort-Creation-For-Deep-MutualLearning/blob/master/KD_Different_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVNpdOWpW0zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2e4265f5-9d39-4d2f-bc97-21210a46d162"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Conv2D,GlobalAveragePooling2D,Dense,Softmax,Flatten,MaxPooling2D,Dropout,Activation, Lambda, concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import kullback_leibler_divergence as KLD_Loss, categorical_crossentropy as logloss\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl78iHAoXBAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "db1a6911-6f25-46a0-8695-aa4a808b7d3e"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# Normalize the dataset\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOv6mJeMXDhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def teacher_generator():\n",
        "  teacher = Sequential() # Must define the input shape in the first layer of the neural network\n",
        "  teacher.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', input_shape=(32,32,3)))\n",
        "  teacher.add(MaxPooling2D(pool_size=2))\n",
        "  teacher.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
        "  teacher.add(MaxPooling2D(pool_size=2))\n",
        "  teacher.add(Flatten())\n",
        "  teacher.add(Dense(256, activation='relu'))\n",
        "  teacher.add(Dense(64, activation='relu',name=\"teacher_target_layer\"))\n",
        "  teacher.add(Dropout(0.5))\n",
        "  teacher.add(Dense(10))\n",
        "  teacher.add(Activation('softmax'))\n",
        "\n",
        "  teacher.compile(loss='sparse_categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "  # Take a look at the model summary\n",
        "\n",
        "  #teacher.summary()\n",
        "\n",
        "  return teacher"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqmahqpKXhpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def student_generator():\n",
        "  student = Sequential() #a Must define the input shape in the first layer of the neural network\n",
        "  student.add(Flatten(input_shape=(32,32,3)))\n",
        "  student.add(Dense(64, activation='relu'))\n",
        "  student.add(Dense(10))\n",
        "  return student"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO0UPrmAYfqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7bae77a-1c23-4968-c920-67b003738b0f"
      },
      "source": [
        "# Instanciating a teacher model and training it ===> for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#                                                                 OFFLINE KNOWLEDGE DISTILLATION\n",
        "\n",
        "\n",
        "teacher_model = teacher_generator()\n",
        "myCP = ModelCheckpoint(save_best_only=True,filepath='teacher_model.h5',monitor = 'val_acc')\n",
        "teacher_model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=128,\n",
        "         epochs=20,\n",
        "         validation_split = 0.2,\n",
        "         callbacks=[myCP])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.7620 - accuracy: 0.3517WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.7620 - accuracy: 0.3517 - val_loss: 1.3774 - val_accuracy: 0.5195\n",
            "Epoch 2/20\n",
            "311/313 [============================>.] - ETA: 0s - loss: 1.3838 - accuracy: 0.5050WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.3840 - accuracy: 0.5052 - val_loss: 1.1682 - val_accuracy: 0.5939\n",
            "Epoch 3/20\n",
            "311/313 [============================>.] - ETA: 0s - loss: 1.2200 - accuracy: 0.5698WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.2200 - accuracy: 0.5698 - val_loss: 1.0764 - val_accuracy: 0.6243\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - ETA: 0s - loss: 1.1054 - accuracy: 0.6130WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.1054 - accuracy: 0.6130 - val_loss: 1.0117 - val_accuracy: 0.6394\n",
            "Epoch 5/20\n",
            "311/313 [============================>.] - ETA: 0s - loss: 1.0387 - accuracy: 0.6422WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.0383 - accuracy: 0.6424 - val_loss: 0.9645 - val_accuracy: 0.6605\n",
            "Epoch 6/20\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.9561 - accuracy: 0.6705WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.9561 - accuracy: 0.6705 - val_loss: 0.9177 - val_accuracy: 0.6801\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.8929 - accuracy: 0.6931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.8929 - accuracy: 0.6931 - val_loss: 0.9193 - val_accuracy: 0.6812\n",
            "Epoch 8/20\n",
            "308/313 [============================>.] - ETA: 0s - loss: 0.8245 - accuracy: 0.7198WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.8243 - accuracy: 0.7200 - val_loss: 0.9095 - val_accuracy: 0.6846\n",
            "Epoch 9/20\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.7683 - accuracy: 0.7353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.7685 - accuracy: 0.7351 - val_loss: 0.8693 - val_accuracy: 0.7031\n",
            "Epoch 10/20\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.7072 - accuracy: 0.7581WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.7075 - accuracy: 0.7580 - val_loss: 0.8947 - val_accuracy: 0.6960\n",
            "Epoch 11/20\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.6501 - accuracy: 0.7778WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.6504 - accuracy: 0.7776 - val_loss: 0.8673 - val_accuracy: 0.7082\n",
            "Epoch 12/20\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.5985 - accuracy: 0.7960WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.5976 - accuracy: 0.7962 - val_loss: 0.8826 - val_accuracy: 0.7176\n",
            "Epoch 13/20\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.5453 - accuracy: 0.8111WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.5459 - accuracy: 0.8109 - val_loss: 0.8959 - val_accuracy: 0.7125\n",
            "Epoch 14/20\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.5089 - accuracy: 0.8261WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.5091 - accuracy: 0.8262 - val_loss: 0.9576 - val_accuracy: 0.6962\n",
            "Epoch 15/20\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.4474 - accuracy: 0.8475WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4474 - accuracy: 0.8475 - val_loss: 1.0094 - val_accuracy: 0.7022\n",
            "Epoch 16/20\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.4085 - accuracy: 0.8603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.4080 - accuracy: 0.8606 - val_loss: 1.0177 - val_accuracy: 0.7083\n",
            "Epoch 17/20\n",
            "309/313 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.8754WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3653 - accuracy: 0.8752 - val_loss: 1.0260 - val_accuracy: 0.7072\n",
            "Epoch 18/20\n",
            "312/313 [============================>.] - ETA: 0s - loss: 0.3214 - accuracy: 0.8897WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.3214 - accuracy: 0.8898 - val_loss: 1.0998 - val_accuracy: 0.7120\n",
            "Epoch 19/20\n",
            "311/313 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2944 - accuracy: 0.8991 - val_loss: 1.1507 - val_accuracy: 0.7077\n",
            "Epoch 20/20\n",
            "310/313 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.9095WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.2622 - accuracy: 0.9094 - val_loss: 1.1983 - val_accuracy: 0.7126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61eb05c400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgAkyZ2AYpiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                                                                OFFLINE KNOWLEDGE DISTILLATION\n",
        "\n",
        "# Phase 1 ===>  re-create the TEACHER model with the softened softmax layer , Using the pre-defined TEMPERATURE\n",
        "\n",
        "teacher_logits_model = Model(teacher_model.input,teacher_model.layers[-2].output)\n",
        "\n",
        "Temperature = 3.25\n",
        "T_layer = Lambda(lambda x:x/Temperature)(teacher_logits_model.output)\n",
        "Softmax_layer = Activation('softmax')(T_layer)\n",
        "teacher_soften_model = Model(teacher_model.input,Softmax_layer)\n",
        "     "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyOb8C9UawVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                                                                OFFLINE KNOWLEDGE DISTILLATION\n",
        "\n",
        "# Phase 2 ===>  Updating the training lables by adding the softened probabilities produced by the pre-trained TEACHER\n",
        "\n",
        "\n",
        "# Predict and convert to sparse categorical matrix\n",
        "y_train_new = teacher_soften_model.predict(x_train)\n",
        "y_test_new = teacher_soften_model.predict(x_test)\n",
        "\n",
        "y_train_new = np.c_[to_categorical(y_train),y_train_new]\n",
        "y_test_new = np.c_[to_categorical(y_test),y_test_new]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JlkWCuObBIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2ab1d91e-36e7-460f-d760-f3e824df7864"
      },
      "source": [
        "#                                                                OFFLINE KNOWLEDGE DISTILLATION\n",
        "\n",
        "# Phase 3 ===>  Instanciating a STUDENT. In default, the student_generator, generates student models that they do not have ACTIVATION in their last layer.\n",
        "# After initializing the student model, we compute the logits, and add the last layer with of SOFTMAX\n",
        "\n",
        "\n",
        "student_model =  student_generator()\n",
        "student_model.summary()\n",
        "\n",
        "student_logits = student_model.layers[-1].output\n",
        "\n",
        "# Compute softmax\n",
        "probs = Activation(\"softmax\")(student_logits)\n",
        "\n",
        "# Compute softmax with softened logits\n",
        "logits_T = Lambda(lambda x:x/Temperature)(student_logits)\n",
        "probs_T = Activation(\"softmax\")(logits_T)\n",
        "\n",
        "CombinedLayers = concatenate([probs,probs_T])\n",
        "\n",
        "student_model_with_softmax = Model(student_model.input,CombinedLayers)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_9 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 64)                196672    \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 197,322\n",
            "Trainable params: 197,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56KuzX4Ab613",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                                                                OFFLINE KNOWLEDGE DISTILLATION\n",
        "\n",
        "# Phase 4 ===>  KNOWLEDGE DISTILLATION custom LOSS\n",
        "\n",
        "def KD_loss(y_true,y_pred,lambd=0.5,T=10.0):\n",
        "  y_true,y_true_KD = y_true[:,:NUM_CLASSES],y_true[:,NUM_CLASSES:]\n",
        "  y_pred,y_pred_KD = y_pred[:,:NUM_CLASSES],y_pred[:,NUM_CLASSES:]\n",
        "  # Classic cross-entropy (without temperature)\n",
        "  CE_loss = logloss(y_true,y_pred)\n",
        "  # KL-Divergence loss for softened output (with temperature)\n",
        "  KL_loss = T**2*KLD_Loss(y_true_KD,y_pred_KD)\n",
        "  \n",
        "  return lambd*CE_loss + (1-lambd)*KL_loss\n",
        "\n",
        "def accuracy(y_true,y_pred):\n",
        "  return categorical_accuracy(y_true,y_pred)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6cnd8mncOZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54ef04bd-5f52-47d1-b68c-31216e1db232"
      },
      "source": [
        "#                                                                OFFLINE KNOWLEDGE DISTILLATION\n",
        "\n",
        "# Phase 5- END ===>  KTraining the complete STUDENT Model with SOFTMAX layer at the end by using the custom  KD LOSS.\n",
        "\n",
        "student_model_with_softmax.compile(optimizer='adam',loss=lambda y_true,y_pred: KD_loss(y_true, y_pred,lambd=0.5,T=Temperature),metrics=[accuracy])\n",
        "myCP = ModelCheckpoint(save_best_only=True,filepath='student_model_trained_regular_kd.h5',monitor = 'val_accuracy')\n",
        "\n",
        "student_model_with_softmax.fit(x_train,y_train_new,epochs=50,validation_split=0.15,batch_size=128,callbacks=[myCP])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 6.2025 - accuracy: 0.2944 - val_loss: 5.3705 - val_accuracy: 0.3236\n",
            "Epoch 2/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 5.6664 - accuracy: 0.3522 - val_loss: 5.1285 - val_accuracy: 0.3569\n",
            "Epoch 3/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 5.4905 - accuracy: 0.3712 - val_loss: 4.9655 - val_accuracy: 0.3657\n",
            "Epoch 4/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 5.3881 - accuracy: 0.3790 - val_loss: 5.2182 - val_accuracy: 0.3509\n",
            "Epoch 5/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 5.2750 - accuracy: 0.3896 - val_loss: 4.9232 - val_accuracy: 0.3751\n",
            "Epoch 6/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 5.1849 - accuracy: 0.3963 - val_loss: 5.1598 - val_accuracy: 0.3381\n",
            "Epoch 7/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 5.1287 - accuracy: 0.4017 - val_loss: 4.6708 - val_accuracy: 0.3987\n",
            "Epoch 8/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 5.0553 - accuracy: 0.4078 - val_loss: 4.6605 - val_accuracy: 0.3924\n",
            "Epoch 9/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 5.0017 - accuracy: 0.4101 - val_loss: 4.7500 - val_accuracy: 0.3792\n",
            "Epoch 10/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.9822 - accuracy: 0.4128 - val_loss: 4.6481 - val_accuracy: 0.3919\n",
            "Epoch 11/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.9285 - accuracy: 0.4168 - val_loss: 4.4924 - val_accuracy: 0.4100\n",
            "Epoch 12/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.8874 - accuracy: 0.4210 - val_loss: 4.5855 - val_accuracy: 0.4013\n",
            "Epoch 13/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.8855 - accuracy: 0.4195 - val_loss: 4.5804 - val_accuracy: 0.3891\n",
            "Epoch 14/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.8283 - accuracy: 0.4250 - val_loss: 4.6187 - val_accuracy: 0.3968\n",
            "Epoch 15/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.8277 - accuracy: 0.4240 - val_loss: 4.5619 - val_accuracy: 0.4017\n",
            "Epoch 16/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.7915 - accuracy: 0.4280 - val_loss: 4.4547 - val_accuracy: 0.4131\n",
            "Epoch 17/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.7586 - accuracy: 0.4313 - val_loss: 4.3868 - val_accuracy: 0.4197\n",
            "Epoch 18/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.7502 - accuracy: 0.4308 - val_loss: 4.5003 - val_accuracy: 0.4041\n",
            "Epoch 19/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.7294 - accuracy: 0.4317 - val_loss: 4.8413 - val_accuracy: 0.3863\n",
            "Epoch 20/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.7280 - accuracy: 0.4300 - val_loss: 4.4788 - val_accuracy: 0.4128\n",
            "Epoch 21/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.7028 - accuracy: 0.4364 - val_loss: 4.3690 - val_accuracy: 0.4179\n",
            "Epoch 22/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.6931 - accuracy: 0.4350 - val_loss: 4.7776 - val_accuracy: 0.3855\n",
            "Epoch 23/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.6818 - accuracy: 0.4373 - val_loss: 4.6443 - val_accuracy: 0.3947\n",
            "Epoch 24/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6692 - accuracy: 0.4388 - val_loss: 4.3330 - val_accuracy: 0.4217\n",
            "Epoch 25/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6488 - accuracy: 0.4409 - val_loss: 4.4934 - val_accuracy: 0.4139\n",
            "Epoch 26/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6605 - accuracy: 0.4378 - val_loss: 4.3509 - val_accuracy: 0.4235\n",
            "Epoch 27/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6188 - accuracy: 0.4413 - val_loss: 4.4347 - val_accuracy: 0.4053\n",
            "Epoch 28/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6173 - accuracy: 0.4431 - val_loss: 4.3381 - val_accuracy: 0.4191\n",
            "Epoch 29/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6103 - accuracy: 0.4433 - val_loss: 4.6494 - val_accuracy: 0.3897\n",
            "Epoch 30/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.6251 - accuracy: 0.4406 - val_loss: 4.3348 - val_accuracy: 0.4196\n",
            "Epoch 31/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.6029 - accuracy: 0.4432 - val_loss: 4.6586 - val_accuracy: 0.3841\n",
            "Epoch 32/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.6069 - accuracy: 0.4421 - val_loss: 4.3623 - val_accuracy: 0.4157\n",
            "Epoch 33/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5855 - accuracy: 0.4456 - val_loss: 4.3156 - val_accuracy: 0.4227\n",
            "Epoch 34/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5799 - accuracy: 0.4451 - val_loss: 4.3613 - val_accuracy: 0.4133\n",
            "Epoch 35/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5767 - accuracy: 0.4452 - val_loss: 4.4452 - val_accuracy: 0.4055\n",
            "Epoch 36/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5608 - accuracy: 0.4487 - val_loss: 4.4091 - val_accuracy: 0.4180\n",
            "Epoch 37/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5530 - accuracy: 0.4489 - val_loss: 4.4822 - val_accuracy: 0.4117\n",
            "Epoch 38/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5629 - accuracy: 0.4456 - val_loss: 4.4369 - val_accuracy: 0.4151\n",
            "Epoch 39/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.5294 - accuracy: 0.4496 - val_loss: 4.3939 - val_accuracy: 0.4188\n",
            "Epoch 40/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.5352 - accuracy: 0.4467 - val_loss: 4.3989 - val_accuracy: 0.4157\n",
            "Epoch 41/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.5206 - accuracy: 0.4520 - val_loss: 4.5729 - val_accuracy: 0.3971\n",
            "Epoch 42/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.5357 - accuracy: 0.4490 - val_loss: 4.4094 - val_accuracy: 0.4155\n",
            "Epoch 43/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.5167 - accuracy: 0.4506 - val_loss: 4.6476 - val_accuracy: 0.4041\n",
            "Epoch 44/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5208 - accuracy: 0.4510 - val_loss: 4.6933 - val_accuracy: 0.3920\n",
            "Epoch 45/50\n",
            "333/333 [==============================] - 2s 6ms/step - loss: 4.5309 - accuracy: 0.4514 - val_loss: 4.2798 - val_accuracy: 0.4321\n",
            "Epoch 46/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.4932 - accuracy: 0.4514 - val_loss: 4.3801 - val_accuracy: 0.4148\n",
            "Epoch 47/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.4880 - accuracy: 0.4539 - val_loss: 4.3228 - val_accuracy: 0.4196\n",
            "Epoch 48/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.4894 - accuracy: 0.4543 - val_loss: 4.3856 - val_accuracy: 0.4188\n",
            "Epoch 49/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5098 - accuracy: 0.4511 - val_loss: 4.4494 - val_accuracy: 0.4151\n",
            "Epoch 50/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 4.5061 - accuracy: 0.4510 - val_loss: 4.3239 - val_accuracy: 0.4193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61eaf606a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHj-SsaDc6D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5132330-9b9d-47ac-d934-c55cea28e6e7"
      },
      "source": [
        "# STANDALONE student model trained from SCRATCH, ONLY From DATASET\n",
        "aloneModel = student_generator()\n",
        "aloneModel.summary()\n",
        "aloneModel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "myCP = ModelCheckpoint(_best_only=True,filepath='alone.h5',monitor = 'val_acc')\n",
        "\n",
        "aloneModel.fit(x_train,y_train,epochs=50,validation_split=0.15,batch_size=128,callbacks=[myCP])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_10 (Flatten)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 64)                196672    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 197,322\n",
            "Trainable params: 197,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 5.7553 - accuracy: 0.0988 - val_loss: 5.3244 - val_accuracy: 0.1015\n",
            "Epoch 2/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.3010 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 3/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 4/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 5/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 6/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 7/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 8/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 9/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 5.2993 - accuracy: 0.0997 - val_loss: 5.3245 - val_accuracy: 0.1015\n",
            "Epoch 10/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 4.6098 - accuracy: 0.1012 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 11/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 12/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 13/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 14/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 15/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 16/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 17/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 18/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 19/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 20/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 21/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 22/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 23/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 24/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 25/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 26/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 27/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 28/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 29/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 30/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 31/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 32/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 33/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 34/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 35/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 36/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 37/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 38/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 39/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 40/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 41/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 42/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 43/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 44/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 45/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 46/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 47/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 48/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 49/50\n",
            "333/333 [==============================] - 1s 4ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n",
            "Epoch 50/50\n",
            "333/333 [==============================] - 2s 5ms/step - loss: 3.8136 - accuracy: 0.1001 - val_loss: 3.7832 - val_accuracy: 0.0999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61e7b7ab70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqEQATZCjbAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#                                                             INTERNAL OFFLINE KNOWLEDGE DISTILLATION\n",
        "# Phase 1 ===>        get the  TARGET layer TEACHER\n",
        "teacher_model\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}